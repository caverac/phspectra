---
sidebar_position: 3
---

# Performance

Plots in this section are generated by

```python
uv run benchmarks performance-plot
```

## Speed comparison

We benchmark the wall-clock time for decomposing all 4200 spectra in the GRS test field (424 channels each) using both PHSpectra and GaussPy+ ([Riener et al. 2019](https://arxiv.org/abs/1906.10506)). Each spectrum is processed individually through the full pipeline of each tool to ensure a fair per-spectrum comparison. Both algorithms are run with their recommended configurations:

- **PHSpectra**: $\beta = 3.8$ (default), C-accelerated Levenberg-Marquardt solver and persistence peak detection
- **GaussPy+**: two-phase decomposition with $\alpha_1 = 2.89$, $\alpha_2 = 6.65$ (trained values from [Riener et al. 2019](https://arxiv.org/abs/1906.10506), Sect. 4.1), SNR threshold = 3.0

### Results

| Metric                    | PHSpectra | GaussPy+  | Factor         |
| ------------------------- | --------- | --------- | -------------- |
| Total time (4200 spectra) | 666.4 s   | 1319.1 s  | **2.0&times;** |
| Mean per spectrum         | 158.7 ms  | 312.9 ms  | 2.0&times;     |
| Median per spectrum       | 31.8 ms   | 34.8 ms   | 1.1&times;     |
| P95 per spectrum          | 510.0 ms  | 583.0 ms  | 1.1&times;     |
| P99 per spectrum          | 3913.8 ms | 7521.4 ms | 1.9&times;     |
| Mean components detected  | 2.35      | 2.44      | &mdash;        |

PHSpectra is **2&times; faster** than GaussPy+ across all metrics. The two tools are now comparable on typical spectra (median 31.8 ms vs 34.8 ms), while PHSpectra maintains a significant advantage on complex spectra where GaussPy+ exhibits long optimization tails (P99 at 3.9 s vs 7.5 s).

![Performance benchmark](/img/results/performance-benchmark.png)

### Timing characteristics

The two tools now have similar median performance but differ in tail behaviour:

- **PHSpectra** matches GaussPy+ on typical spectra and is faster across the board. A custom C extension implements both the bounded Levenberg-Marquardt solver (with analytic Jacobian) and the persistence-based peak detection, eliminating the Python-to-Fortran boundary crossing overhead that previously dominated per-call cost. The result is a tighter timing distribution with fewer extreme outliers.

- **GaussPy+** has comparable median performance but much higher variance. A small fraction of spectra trigger long optimization chains, with P99 reaching 7.5 s. These outliers dominate the mean and total time.

### Algorithmic differences

1. **No smoothing sweep.** GaussPy+ convolves the spectrum with a family of Gaussian kernels at each $\alpha$ scale, computing derivatives at every scale. The two-phase decomposition repeats this process twice (once per $\alpha$). PHSpectra skips smoothing entirely &mdash; it operates directly on the raw spectrum using persistence-based peak detection, which is $O(n)$ in the number of channels.

2. **No training required.** GaussPy+'s $\alpha$ parameters must be trained per survey (or per survey region), which adds a separate computational cost not reflected in the per-spectrum timing. PHSpectra's $\beta$ parameter requires no training &mdash; the default value works across surveys.

3. **Tail behaviour.** PHSpectra's execution time is more predictable. GaussPy+'s derivative-based approach can trigger costly iterative refinement on complex spectra, leading to extreme outliers that dominate aggregate timing.

### Benchmark details

- **Hardware**: single-core sequential processing for both tools (no parallelization)
- **PHSpectra**: native Python 3.14, C extension for LM solver and peak detection
- **GaussPy+**: Python 3.10 in Docker (required for compatibility with legacy numpy/scipy); each spectrum is processed individually through the full `GaussPyDecompose` pipeline (init, decompose, improve_fitting, save)
- **Spectra**: all 4200 GRS test-field pixels, 424 velocity channels each
